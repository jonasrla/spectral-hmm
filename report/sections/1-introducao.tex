\documentclass{subfiles}

\begin{document}

Este é um trabalho com o objetivo de comparar duas implementações de algoritmos de aprendizagem de \textit{Cadeias Ocultas de Markov}. Além disso, uma rápida introdução bibliográfica será feita para ambientar o leitor dos temas a serem tratados no trabalho, da perspectiva do campo de probabilidade e modelos estatísticos. 

Começaremos apresentando as \textit{Cadeias de Markov}. Nesta primeira seção um exemplo de estimativa de modelo será exposto, algo que será bastante ilustrativo do objetivo final do trabalho. Alguns conceitos e ilustrações iram ajudar o leitor a se familiarizar com os conceitos bases deste modelo estatístico

Na seção seguinte, serão expostas as modificações necessárias para sairmos da cadeia para os \textit{Modelos Ocultos de Markov}. Nesta sessão serão apresentadas as notações adicionais e algumas problemas, ou perguntas, que serão feitas em relação ao modelo. Uma dessas perguntas ficará evidente que só se aplicará para modelos iterativos como é o caso método de \textit{Baum-Weich}, mas a maioria dos problemas que já são contemplados pela forma canônica também serão pela \textit{Aprendizagem Espectral}.

Na terceira seção, enfim os elementos da representação alternativa dos \textit{Modelos Ocultos de Markov} é apresentado. Além disso, serão apresentadas as formas de se calcular cada resolução dos problemas dos \textit{Modelos Ocultos de Markov} com suas respectivas referências das demonstrações no texto original em que foram apresentadas.

Na quarta seção dos experimentos, apresentarei alguns resultados alcançados ao se comparar uma implementação do algoritmo de \textit{Aprendizagem Espectral} e o método de \textit{Baum-Weich}. Será apresentado com elementos gráficos a troca entre rapidez e precisão dos modelos.

Na quinta e última, serão apresentados algumas questões adicionais, como as frequentes estimativas de probabilidade negativa e entre outras comparações que não foram possíveis de se fazer neste trabalho.

\end{document}
