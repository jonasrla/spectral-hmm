\documentclass{subfiles}

\begin{document}

\textit{Cadeia de Markov} é um processo estocástico no qual a probabilidade do próximo estado depende apenas do estado anterior. Se o processo ainda tiver uma quantidade finita de estados e o tempo for discreto, é possível representar a cadeia como grafo direcionado completo como representado na Figura \ref{fig:auto_rep}. Cada estado corresponde a um nó do grafo, partindo de cada nó o estado seguinte é uma variável aleatória com as probabilidades representadas nos pesos de cada aresta. Por tanto, no caso ilustrado na Figura \ref{fig:auto_rep}
\begin{gather*}
	\text{Para todo } e, e^\prime \in E = \{A, B, C\} \\
	P(e^\prime|e) \in [0, 1] \text{ e }\\
	P(A|e) + P(B|e) + P(C|e) = 1
\end{gather*}
Como se espera de uma função probabilidade com domínio discreto. A partir do grafo é bastante direto representar os parâmetros de forma matricial
\[
    T = \begin{pmatrix}
        P(A|A) & P(B|A) & P(C|A) \\
        P(A|B) & P(B|B) & P(C|B) \\
        P(A|C) & P(B|C) & P(C|C)
    \end{pmatrix}
\]

Por outro lado, há redundâncias na matriz, pois cada linha soma $1$, por isso é suficiente $6$ parâmetros para determinar uma cadeia de $3$ estados. Além disso, existe uma distribuição de probabilidade para o valor inicial da sequência que será representado como $\pi_0(e)$ que é equivalente ao vetor
\[
	\Pi_0 = \begin{pmatrix}
		\pi_0(A) \\
		\pi_0(B) \\
		\pi_0(C)
	\end{pmatrix}
\]

De forma geral, em uma \textit{Cadeia de Markov} com $n$ estados, são necessários $n^2 - n$ parâmetros e cada probabilidade condicional é representada numa matriz $T \in \mathbb{R}^{n \times n}$ com entradas não negativas e que
\[
	T \mathbf{1}_n = \mathbf{1}_n
\]
Isto é, cada linha soma $1$. Além disso, também vetor $\Pi_0 \in \mathbb{R}^n$ com a distribuição de probabilidades para o estado inicial que também somam 1:
\[
	\Pi_0^{\mathrm T} \mathbf{1}_n = 1
\]
E da mesma forma que a matriz transição, à redundância no vetor $\Pi_0$, pois é suficiente determinar apenas as probabilidades de $n-1$ estados.

Concluí-se que uma \textit{Cadeia de Markov} de $n$ estados é definida por $n^2-1$ parâmetros.

\begin{figure}
	\includegraphics[width=\linewidth]{markov_chain.png}
	\caption{Exemplo de diagrama de estados de uma \textit{Cadeia de Markov} com $3$}
	\label{fig:auto_rep}
\end{figure}

\subsection{Estimativa de parâmetros} \label{sub:exemplo}

Considere o seguinte conjunto sequências
\begin{align*}
	&ABCABACCACAB         \\
	&BACABACAAC           \\
	&BBABAAAACCACABABABAC
\end{align*}

Assumindo a premissa de que tais sequências foram geradas por um processo modelável como \textit{Cadeia de Markov}, os parâmetros de tal cadeia serão estimados. É urgente se observar que as sequências apresentam apenas $3$ estados. Por tanto, a matriz transição $T \mathbb{R}^{3 \times 3}$ e $\Pi_0 \in \mathbb{R}^3$.

No total, há $20$ ocorrências da letra $A$ seguida de algum estado, $10$ da $B$, e $9$ da $C$. Ao se contar cada ocorrência das tuplas $AA$, $AB$, $AC$, e assim por diante, dividindo pela ocorrência do respectivo estado antecessor. Assim a seguinte matriz transição é obtida
\[
    T = \begin{pmatrix}
        \frac{4}{20} & \frac{8}{20} & \frac{8}{20} \\
        \frac{8}{10} & \frac{1}{10} & \frac{1}{10} \\
        \frac{7}{9} & \frac{0}{9} & \frac{2}{9}
    \end{pmatrix}
\]

Já para a estimativa do vetor probabilidade de estado inicial $\Pi_0$, o processo é imediato, é a frequência pela quantidade de sequências
\[
	\Pi_0 = \begin{pmatrix}
		\frac{1}{3} & \frac{2}{3} & 0
	\end{pmatrix}
\]

\subsection{Probabilidade de uma sequência}

\begin{figure}
	\includegraphics[width=\linewidth]{seq_markov_chain.png}
	\caption{Visualização sequencial da \textit{Cadeia de Markov} de distribuição de probabilidade inicial $\Pi_0$ e matriz transição $T$}
	\label{fig:seq_mc}
\end{figure}

O interesse nesta subseção é de calcular, partindo dos parâmetros que descrevem uma \textit{Cadeia de Markov}, a probabilidade de cada sequência de estados. Seja $(e_i)_{i=1}^t$ um processo de Markov que gere uma sequência de estados de uma \textit{Cadeia de Markov} que tenha probabilidade inicial $\Pi_0$ e uma matriz transferência de estados $T$, como ilustrado na figura \ref{fig:seq_mc}. Como Bishop \autocite{Bishop:2006pat} apresenta, a transferência de estado só depende do estado anterior, que simplifica bastante o cálculo da probabilidade conjunta a partir das probabilidades condicionais
\begin{gather*}
	P((e_k)_{k=1}^t) = P(e_1) \prod_{k=2}^t P(e_{k} \vert e_{k-1}) \\
	\Rightarrow P((e_k)_{k=1}^t) = \Pi_0[i=e_1] \prod_{k=2}^t T[i=e_{k-1},\, j=e_{k}]
\end{gather*}

No caso do modelo da seção anterior, a sequência $BACABBAC$ tem probabilidade
\begin{gather*}
	P(BACABBAC) = P(B) P(A|B) P(C|A) P(A|C) \\
	P(B|A) P(B|B) P(A|B) P(C|A) \\
	= 2/3 8/10 8/20 7/9 8/20 1/10 8/10 8/20 \approx 2.212 * 10^{-3}
\end{gather*}

O leitor mais atento observou que a medida que as sequências crescem elas se tornam mais improváveis, por isso deve haver uma precaução na manipulação dessas probabilidades e evitar comparar sequências de tamanhos diferentes.

% \subsection{Probabilidade Estacionária}

% Finalizaremos fazendo algumas observações sobre convergência desses processos.
% Agora suponha que algum processo é caracterizado como \textit{Cadeia de Markov} tenha matriz transição $T$, então note
% \[
% 	(T - I)\mathbf{1} = T\mathbf{1} - I\mathbf{1} = \mathbf{1} - \mathbf{1} = O
% \]
% Isto é, tal matriz é $T - I$ não é linearmente independente e por tanto, tem determinante $0$. Isto implica que $1$ é autovalor da matriz $T$. Por tanto existe um vetor linha $V$ tal que
% \[
% 	VT = V
% \]
% Como todas entradas de $T$ são não-negativas, $V$ só pode ter entradas não-negativas. Além disso, podemos multiplicar a igualdade por qualquer escalar em ambos os lados que a igualdade se mantém, por isso podemos forçar que $V\mathbf{1} = 1$. Chama-se $V$ de \textit{Probabilidade Estacionária}, isto é, a distribuição de probabilidade dos estados converge para $V$

% \subsection{Modelos com dependência}
% Há também a possibilidade de expandir o modelo adicionando mais estados na dependência do estado seguinte, como Bishop\autocite{Bishop:2006pat} discute, mas isso vem com o custo de mais variáveis na matriz transferência para se calcular. Se $n$ é número de estados e $d$ o número de extensão de dependência, então, a quantidade de parâmetros necessários para descrever a transição é $n^d(n-1)$

% Este nível de detalhamento pode tornar o modelo impraticável quando esta expansão se torna muito grande. Além disso, as estimativas dos parâmetros desse modelo passa depender de mais observações. No exemplo da seção \ref{sub:exemplo} não há ocorrências do par $CB$. Isto pode ter sido causado pelo fato de que o processo não permita essa transição de estado, mas também é possível que essa transição só não tenha sido observada na amostra apresentada.

\end{document}